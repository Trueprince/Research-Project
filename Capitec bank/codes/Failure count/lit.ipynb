{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fa340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "from lit_nlp import notebook\n",
    "from lit_nlp.api import dataset as lit_dataset\n",
    "from lit_nlp.api import types as lit_types\n",
    "from lit_nlp.api import model as lit_model\n",
    "from lit_nlp.components import metrics as lit_metrics\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- Dataset Wrapper ----------------\n",
    "class FocusDFDataset(lit_dataset.Dataset):\n",
    "    \"\"\"Expose focus_df columns for LIT (with percentages and risk).\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self._examples = []\n",
    "        for _, row in df.iterrows():\n",
    "            self._examples.append({\n",
    "                \"text\": row[\"Content\"],\n",
    "                \"day\": str(row[\"Day\"]),\n",
    "                \"predicted_percent\": float(row[\"Predicted_Percent\"]),\n",
    "                \"failure_risk\": str(row[\"Failure_Risk\"])\n",
    "            })\n",
    "\n",
    "    def spec(self):\n",
    "        return {\n",
    "            \"text\": lit_types.TextSegment(),\n",
    "            \"day\": lit_types.TextSegment(),\n",
    "            \"predicted_percent\": lit_types.RegressionScore(),\n",
    "            \"failure_risk\": lit_types.CategoryLabel(vocab=[\"Safe\", \"At Risk\"])\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def examples(self):\n",
    "        return self._examples\n",
    "\n",
    "\n",
    "# ---------------- LIT Model Wrapper w/ LIME ----------------\n",
    "class LITLIMEModel(lit_model.Model):\n",
    "    \"\"\"LIT-compatible wrapper to show predicted_percent & failure risk with LIME.\"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.explainer = LimeTextExplainer(class_names=[\"Safe\", \"At Risk\"])\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"Return LIT-compatible outputs.\"\"\"\n",
    "        outputs = []\n",
    "        for ex in inputs:\n",
    "            text = ex[\"text\"]\n",
    "            row = self.df[self.df[\"Content\"] == text]\n",
    "            if len(row) == 0:\n",
    "                risk_prob = 0.0\n",
    "            else:\n",
    "                risk_prob = row[\"Predicted_Percent\"].values[0] / 100\n",
    "            outputs.append({\n",
    "                \"Safe\": 1 - risk_prob,\n",
    "                \"At Risk\": risk_prob\n",
    "            })\n",
    "        return outputs\n",
    "\n",
    "    def input_spec(self):\n",
    "        return {\"text\": lit_types.TextSegment()}\n",
    "\n",
    "    def output_spec(self):\n",
    "        return {\n",
    "            \"Safe\": lit_types.RegressionScore(),\n",
    "            \"At Risk\": lit_types.RegressionScore()\n",
    "        }\n",
    "\n",
    "    def explain_instance(self, text):\n",
    "        \"\"\"Get top LIME tokens for a single text instance.\"\"\"\n",
    "        exp = self.explainer.explain_instance(\n",
    "            text_instance=text,\n",
    "            classifier_fn=lambda x: np.array([list(d.values()) for d in self.predict([{\"text\": t} for t in x])]),\n",
    "            num_features=10\n",
    "        )\n",
    "        return exp.as_list()\n",
    "\n",
    "\n",
    "# ---------------- Compute failure risk from focus_df ----------------\n",
    "FAILURE_THRESHOLD_RATIO = 50\n",
    "focus_df[\"Failure_Risk\"] = np.where(\n",
    "    focus_df[\"Predicted_Percent\"] > FAILURE_THRESHOLD_RATIO,\n",
    "    \"At Risk\",\n",
    "    \"Safe\"\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------- Launch LIT ----------------\n",
    "regression_metrics = lit_metrics.RegressionMetrics()\n",
    "\n",
    "widget = notebook.LitWidget(\n",
    "    models={\"focus_df_lime\": LITLIMEModel(focus_df)},\n",
    "    datasets={\"focus_df_data\": FocusDFDataset(focus_df)},\n",
    "    metrics={\"regression\": regression_metrics},\n",
    "    port=9004\n",
    ")\n",
    "\n",
    "widget.render(height=900)\n",
    "print(\"ðŸ”— Access LIT in your browser at: http://localhost:9004\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff61ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = TextToBiLSTMModel(\n",
    "    keras_model=model,              # Your trained GRU/LSTM model\n",
    "    sentence_model=sentence_model,  # SentenceTransformer embeddings\n",
    "    vectorizer=vectorizer,          # CountVectorizer for LDA\n",
    "    lda_model=lda_final,            # Trained LDA model\n",
    "    scaler_embed=scaler_embed,      # Scaler fitted on embeddings\n",
    "    scaler_y=scaler_y,              # Scaler fitted on original targets\n",
    "    model_feature_dim=X_seq.shape[2],  # Input feature dimension for model\n",
    "    failure_threshold=FAILURE_THRESHOLD_RATIO  # Can now set as % threshold\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from lit_nlp.components import lime_explainer\n",
    "from lit_nlp.api import dataset as lit_dataset\n",
    "from lit_nlp.api import types as lit_types\n",
    "\n",
    "# ---------------- Dataset Wrapper for focus_df ----------------\n",
    "class FocusDFDataset(lit_dataset.Dataset):\n",
    "    \"\"\"Expose focus_df columns for LIME / LIT.\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self._examples = []\n",
    "        for _, row in df.iterrows():\n",
    "            self._examples.append({\n",
    "                \"text\": row[\"Content\"],\n",
    "                \"day\": str(row[\"Day\"]),\n",
    "                \"actual_failures\": float(row[\"Actual_Failures\"]),\n",
    "                \"predicted_failures\": float(row[\"Predicted_Failures\"]),\n",
    "                \"actual_percent\": float(row[\"Actual_Percent\"]),\n",
    "                \"predicted_percent\": float(row[\"Predicted_Percent\"]),\n",
    "                \"failure_risk\": str(row[\"Failure_Risk\"])\n",
    "            })\n",
    "\n",
    "    def spec(self):\n",
    "        return {\n",
    "            \"text\": lit_types.TextSegment(),\n",
    "            \"day\": lit_types.TextSegment(),\n",
    "            \"actual_failures\": lit_types.RegressionScore(),\n",
    "            \"predicted_failures\": lit_types.RegressionScore(),\n",
    "            \"actual_percent\": lit_types.RegressionScore(),\n",
    "            \"predicted_percent\": lit_types.RegressionScore(),\n",
    "            \"failure_risk\": lit_types.CategoryLabel(vocab=[\"Safe\", \"At Risk\"])\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def examples(self):\n",
    "        return self._examples\n",
    "\n",
    "# Create dataset instance\n",
    "focus_dataset = FocusDFDataset(focus_df)\n",
    "\n",
    "# ---------------- Use your corrected model wrapper ----------------\n",
    "lit_model_wrapper = model_wrapper  # TextToBiLSTMModel\n",
    "\n",
    "# ---------------- Pick an instance ----------------\n",
    "instance_idx = 95\n",
    "instance_95 = focus_dataset.examples[instance_idx]\n",
    "\n",
    "# ---------------- Initialize LIME explainer ----------------\n",
    "lime = lime_explainer.LIME()\n",
    "\n",
    "# ---------------- Run LIME ----------------\n",
    "lime_results = lime.run([instance_95], model=lit_model_wrapper, dataset=focus_dataset)\n",
    "result_95 = lime_results[0]\n",
    "\n",
    "# ---------------- Extract TokenSalience ----------------\n",
    "token_salience_obj = result_95['text']\n",
    "tokens = token_salience_obj.tokens\n",
    "salience = token_salience_obj.salience\n",
    "\n",
    "# ---------------- Aggregate salience for repeated tokens ----------------\n",
    "df_plot = pd.DataFrame({\"Token\": tokens, \"Importance\": salience})\n",
    "df_plot = df_plot.groupby(\"Token\").mean().reset_index()\n",
    "\n",
    "# ---------------- Get top positive and negative tokens ----------------\n",
    "df_top = pd.concat([\n",
    "    df_plot.nlargest(10, \"Importance\"),\n",
    "    df_plot.nsmallest(10, \"Importance\")\n",
    "])\n",
    "df_top_sorted = df_top.sort_values(\"Importance\")\n",
    "\n",
    "# ---------------- Interactive Plot ----------------\n",
    "fig = px.bar(\n",
    "    df_top_sorted,\n",
    "    x=\"Importance\",\n",
    "    y=\"Token\",\n",
    "    orientation='h',\n",
    "    color=\"Importance\",\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    title=\"Top Positive & Negative Tokens  (LIME-based)\",\n",
    "    labels={\"Importance\": \"LIME Importance\", \"Token\": \"Tokens\"},\n",
    "    hover_data={\"Importance\": True, \"Token\": True}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"LIME Importance (Effect on Prediction)\",\n",
    "    yaxis_title=\"Tokens\",\n",
    "    template=\"plotly_white\",\n",
    "    height=600,\n",
    "    margin=dict(l=150, r=50, t=50, b=50)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# ---------------- Optional: Print top tokens ----------------\n",
    "top_positive_tokens = df_plot.nlargest(10, \"Importance\")[\"Token\"].tolist()\n",
    "top_negative_tokens = df_plot.nsmallest(10, \"Importance\")[\"Token\"].tolist()\n",
    "\n",
    "print(\"Example 95 Text:\\n\", instance_95['text'], \"\\n\")\n",
    "print(\"Top Positive Tokens:\", top_positive_tokens)\n",
    "print(\"Top Negative Tokens:\", top_negative_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "from lit_nlp import notebook\n",
    "from lit_nlp.api import dataset as lit_dataset\n",
    "from lit_nlp.api import types as lit_types\n",
    "from lit_nlp.components import metrics as lit_metrics\n",
    "from lit_nlp.components import lime_explainer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------- Compute additional columns ----------------\n",
    "# Convert failures to percentage of total count\n",
    "focus_df['Actual_Percent'] = (focus_df['Actual_Failures'] / focus_df['Total_Count']) * 100\n",
    "focus_df['Predicted_Percent'] = (focus_df['Predicted_Failures'] / focus_df['Total_Count']) * 100\n",
    "\n",
    "# Compute failure risk (50% threshold)\n",
    "FAILURE_THRESHOLD_RATIO = 50  # percent\n",
    "focus_df['Failure_Risk'] = np.where(focus_df['Predicted_Percent'] > FAILURE_THRESHOLD_RATIO, 'At Risk', 'Safe')\n",
    "\n",
    "# ---------------- Dataset Wrapper ----------------\n",
    "class FocusDFDataset(lit_dataset.Dataset):\n",
    "    \"\"\"Expose focus_df columns with true_score for LIT + LIME.\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self._examples = []\n",
    "        for _, row in df.iterrows():\n",
    "            self._examples.append({\n",
    "                \"text\": row[\"Content\"],\n",
    "                \"day\": str(row[\"Day\"]),\n",
    "                \"true_score\": float(row[\"Actual_Failures\"]),  # Required by model\n",
    "                \"predicted_score\": float(row[\"Predicted_Failures\"]),\n",
    "                \"actual_percent\": float(row[\"Actual_Percent\"]),\n",
    "                \"predicted_percent\": float(row[\"Predicted_Percent\"]),\n",
    "                \"failure_risk\": str(row[\"Failure_Risk\"])\n",
    "            })\n",
    "\n",
    "    def spec(self):\n",
    "        return {\n",
    "            \"text\": lit_types.TextSegment(),\n",
    "            \"day\": lit_types.TextSegment(),\n",
    "            \"true_score\": lit_types.RegressionScore(),\n",
    "            \"predicted_score\": lit_types.RegressionScore(),\n",
    "            \"actual_percent\": lit_types.RegressionScore(),\n",
    "            \"predicted_percent\": lit_types.RegressionScore(),\n",
    "            \"failure_risk\": lit_types.CategoryLabel(vocab=[\"Safe\", \"At Risk\"])\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def examples(self):\n",
    "        return self._examples\n",
    "\n",
    "# Create dataset instance\n",
    "focus_dataset = FocusDFDataset(focus_df)\n",
    "\n",
    "# ---------------- Model Wrapper ----------------\n",
    "class TextToBiLSTMModel:\n",
    "    \"\"\"Wrapper to feed Text + embeddings into your trained RNN/GRU model.\"\"\"\n",
    "\n",
    "    def __init__(self, keras_model, sentence_model, vectorizer, lda_model, scaler_embed, scaler_y, model_feature_dim, failure_threshold=3.0):\n",
    "        self.model = keras_model\n",
    "        self.sentence_model = sentence_model\n",
    "        self.vectorizer = vectorizer\n",
    "        self.lda_model = lda_model\n",
    "        self.scaler_embed = scaler_embed\n",
    "        self.scaler_y = scaler_y\n",
    "        self.model_feature_dim = model_feature_dim\n",
    "        self.failure_threshold = failure_threshold\n",
    "\n",
    "    def text_to_combined_vector(self, text_list):\n",
    "        embed_vecs = self.sentence_model.encode(text_list)\n",
    "        counts = self.vectorizer.transform(text_list)\n",
    "        lda_vecs = self.lda_model.transform(counts)\n",
    "        return np.hstack([embed_vecs, lda_vecs])\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        texts = [ex[\"text\"] for ex in inputs]\n",
    "        embeddings = self.text_to_combined_vector(texts)\n",
    "        X_scaled = self.scaler_embed.transform(embeddings)\n",
    "\n",
    "        # Pad/trim to model_feature_dim\n",
    "        curr_dim = X_scaled.shape[1]\n",
    "        if curr_dim < self.model_feature_dim:\n",
    "            pad = np.zeros((X_scaled.shape[0], self.model_feature_dim - curr_dim))\n",
    "            X_final = np.hstack([X_scaled, pad])\n",
    "        else:\n",
    "            X_final = X_scaled[:, :self.model_feature_dim]\n",
    "\n",
    "        # GRU expects sequence of length 3\n",
    "        seq_len = 3\n",
    "        X_seq_input = np.array([np.tile(X_final[i], (seq_len, 1)) for i in range(len(X_final))], dtype=np.float32)\n",
    "\n",
    "        # Model prediction\n",
    "        preds_scaled = self.model.predict(X_seq_input, verbose=0).flatten()\n",
    "        preds_actual = self.scaler_y.inverse_transform(preds_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "        outputs = []\n",
    "        for p, ex in zip(preds_actual, inputs):\n",
    "            risk_label = \"At Risk\" if p > self.failure_threshold else \"Safe\"\n",
    "            outputs.append({\n",
    "                \"predicted_score\": float(p),\n",
    "                \"true_score\": float(ex[\"true_score\"]),  # âœ… Now exists\n",
    "                \"failure_risk\": risk_label\n",
    "            })\n",
    "        return outputs\n",
    "\n",
    "# ---------------- Initialize model wrapper ----------------\n",
    "lit_model_wrapper = TextToBiLSTMModel(\n",
    "    keras_model=model,\n",
    "    sentence_model=sentence_model,\n",
    "    vectorizer=vectorizer,\n",
    "    lda_model=lda_final,\n",
    "    scaler_embed=scaler_embed,\n",
    "    scaler_y=scaler_y,\n",
    "    model_feature_dim=X_seq.shape[2],\n",
    "    failure_threshold=3.0\n",
    ")\n",
    "\n",
    "# ---------------- Metrics ----------------\n",
    "regression_metrics = lit_metrics.RegressionMetrics()  # optional\n",
    "\n",
    "# ---------------- Launch LIT ----------------\n",
    "widget = notebook.LitWidget(\n",
    "    models={\"focus_df_lime\": lit_model_wrapper},\n",
    "    datasets={\"focus_df_data\": focus_dataset},\n",
    "    metrics={\"regression\": regression_metrics},\n",
    "    port=9004\n",
    ")\n",
    "\n",
    "widget.render(height=900)\n",
    "print(\"ðŸ”— Access LIT in your browser at: http://localhost:9004\")\n",
    "\n",
    "# ---------------- LIME Explainer for a single instance ----------------\n",
    "instance_95 = focus_dataset.examples[95]\n",
    "\n",
    "lime = lime_explainer.LIME()\n",
    "lime_results = lime.run([instance_95], model=lit_model_wrapper, dataset=focus_dataset)\n",
    "result_95 = lime_results[0]\n",
    "\n",
    "# ---------------- Extract token-level salience ----------------\n",
    "tokens = result_95['text'].tokens\n",
    "salience = result_95['text'].salience\n",
    "\n",
    "# ---------------- Aggregate repeated tokens ----------------\n",
    "df_plot = pd.DataFrame({\"Token\": tokens, \"Importance\": salience})\n",
    "df_plot = df_plot.groupby(\"Token\").mean().reset_index()\n",
    "\n",
    "# ---------------- Top positive & negative tokens ----------------\n",
    "df_top = pd.concat([df_plot.nlargest(10, \"Importance\"), df_plot.nsmallest(10, \"Importance\")])\n",
    "df_top_sorted = df_top.sort_values(\"Importance\")\n",
    "\n",
    "# ---------------- Optional: Print top tokens ----------------\n",
    "top_positive_tokens = df_plot.nlargest(10, \"Importance\")[\"Token\"].tolist()\n",
    "top_negative_tokens = df_plot.nsmallest(10, \"Importance\")[\"Token\"].tolist()\n",
    "\n",
    "print(\"Example 95 Text:\\n\", instance_95['text'], \"\\n\")\n",
    "print(\"Top Positive Tokens:\", top_positive_tokens)\n",
    "print(\"Top Negative Tokens:\", top_negative_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464d9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from lit_nlp.components import lime_explainer\n",
    "\n",
    "# ---------------- Use your corrected model wrapper ----------------\n",
    "lit_model_wrapper = model_wrapper  # model_wrapper must be TextToRNN_GRUModel\n",
    "\n",
    "# ---------------- Pick an instance ----------------\n",
    "# Use the LIT dataset wrapper instead of the raw DataFrame\n",
    "instance_95 = focus_dataset.examples[95]  # âœ… focus_dataset has `examples`\n",
    "\n",
    "# ---------------- Initialize LIME explainer ----------------\n",
    "lime = lime_explainer.LIME()\n",
    "\n",
    "# ---------------- Run LIME ----------------\n",
    "lime_results = lime.run([instance_95], model=lit_model_wrapper, dataset=focus_dataset)\n",
    "result_95 = lime_results[0]\n",
    "\n",
    "# ---------------- Extract TokenSalience ----------------\n",
    "token_salience_obj = result_95['text']\n",
    "tokens = token_salience_obj.tokens\n",
    "salience = token_salience_obj.salience\n",
    "\n",
    "# ---------------- Aggregate salience for repeated tokens ----------------\n",
    "df_plot = pd.DataFrame({\"Token\": tokens, \"Importance\": salience})\n",
    "df_plot = df_plot.groupby(\"Token\").mean().reset_index()  # average salience per token\n",
    "\n",
    "# ---------------- Get top positive and negative tokens ----------------\n",
    "df_top = pd.concat([\n",
    "    df_plot.nlargest(10, \"Importance\"),\n",
    "    df_plot.nsmallest(10, \"Importance\")\n",
    "])\n",
    "df_top_sorted = df_top.sort_values(\"Importance\")\n",
    "\n",
    "# ---------------- Interactive Plot ----------------\n",
    "fig = px.bar(\n",
    "    df_top_sorted,\n",
    "    x=\"Importance\",\n",
    "    y=\"Token\",\n",
    "    orientation='h',\n",
    "    color=\"Importance\",\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    title=\"Top Positive & Negative Tokens  (LIME-based)\",\n",
    "    labels={\"Importance\": \"LIME Importance\", \"Token\": \"Tokens\"},\n",
    "    hover_data={\"Importance\": True, \"Token\": True}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"LIME Importance (Effect on Prediction)\",\n",
    "    yaxis_title=\"Tokens\",\n",
    "    template=\"plotly_white\",\n",
    "    height=600,\n",
    "    margin=dict(l=150, r=50, t=50, b=50)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# ---------------- Optional: Print top tokens ----------------\n",
    "top_positive_tokens = df_plot.nlargest(10, \"Importance\")[\"Token\"].tolist()\n",
    "top_negative_tokens = df_plot.nsmallest(10, \"Importance\")[\"Token\"].tolist()\n",
    "\n",
    "print(\"Example 95 Text:\\n\", instance_95['text'], \"\\n\")\n",
    "print(\"Top Positive Tokens:\", top_positive_tokens)\n",
    "print(\"Top Negative Tokens:\", top_negative_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
